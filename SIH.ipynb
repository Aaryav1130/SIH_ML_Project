{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "VHf1J_4rZYqy",
    "outputId": "a4b9645a-4b58-41a3-a35b-33cacf235b65"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"tsunami_tweets.csv\")\n",
    "\n",
    "# Rename columns to standard names\n",
    "df.rename(columns={\n",
    "    'Created At': 'date',\n",
    "    'Likes': 'like_count',\n",
    "    'Retweets': 'retweet_count'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert date column\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "# Group by date to sum engagements\n",
    "engagement = df.groupby('date')[['like_count', 'retweet_count']].sum().reset_index()\n",
    "\n",
    "# Prepare data for heatmap\n",
    "heatmap_data = engagement.set_index('date').T\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 5))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"YlOrRd\",\n",
    "    annot=False,  # change to True if you want numbers in cells\n",
    "    cbar_kws={'label': 'Engagement Count'}\n",
    ")\n",
    "\n",
    "plt.title(\"Tsunami Tweets Engagement Heatmap (Likes & Retweets over Time)\", fontsize=14)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UjUDXMuaFFR",
    "outputId": "ba0d2912-d152-468c-8777-fdc8e1644b8a"
   },
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2813fd71c87649598106339743772d00",
      "25809994774f4aa2a0fad898bee28e8a",
      "d8448abbe90943f2a4393ac311a0ccc5",
      "6ea4477c4ad64b3abd2a7d5ec4d1e72b",
      "24bebe355afd4e91880e18f6936c0b94",
      "6e6af3afa3e64ee0bb832dbb3f0d720c",
      "ee0b0ff287c1408a86b29235a8356342",
      "1e5099a951a9430f80efca0ea00028c7",
      "aa4956639cf941f39dd0745c7cbb052d",
      "4056309a318b4367aafe0c99068a9503",
      "9adb8effc0ef4b94b030bb1410756617"
     ]
    },
    "id": "0PdRCv3XaWM2",
    "outputId": "6429428f-3737-4cd8-bbca-e2a290c15169"
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch pandas matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"tsunami_tweets.csv\")\n",
    "\n",
    "# Rename for consistency\n",
    "df.rename(columns={'Created At': 'date', 'Text': 'text'}, inplace=True)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "# Load sentiment model\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    words = []\n",
    "    for word in str(tweet).split(\" \"):\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http'):\n",
    "            word = \"http\"\n",
    "        words.append(word)\n",
    "    return \" \".join(words)\n",
    "\n",
    "def get_sentiment(tweet):\n",
    "    tweet_proc = preprocess_tweet(tweet)\n",
    "    encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "    output = model(**encoded_tweet)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return labels[np.argmax(scores)]  # return label with highest score\n",
    "\n",
    "# Run sentiment analysis\n",
    "tqdm.pandas()\n",
    "df['sentiment'] = df['text'].progress_apply(get_sentiment)\n",
    "\n",
    "# Count tweets per sentiment per date\n",
    "sentiment_trend = df.groupby(['date', 'sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(sentiment_trend.index, sentiment_trend['Positive'], label=\"Positive\", color=\"green\", marker='o')\n",
    "plt.plot(sentiment_trend.index, sentiment_trend['Neutral'], label=\"Neutral\", color=\"blue\", marker='o')\n",
    "plt.plot(sentiment_trend.index, sentiment_trend['Negative'], label=\"Negative\", color=\"red\", marker='o')\n",
    "\n",
    "plt.title(\"Sentiment Trend for 'Tsunami' Tweets\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
